# Job Market Intelligence Scraper ğŸš€

A production-style **job market data pipeline** that scrapes RemoteOK, stores structured job data in PostgreSQL, extracts in-demand skills, and exports clean CSV reports for analysis and dashboards.

This project demonstrates **end-to-end data engineering**: scraping, persistence, transformation, analytics, and automation.

---

## ğŸ”§ Tech Stack

- **Python 3.12**
- **Selenium + BeautifulSoup** (dynamic scraping)
- **PostgreSQL**
- **SQLAlchemy 2.0 + Alembic**
- **Pandas**
- **GitHub Actions (scheduled automation)**

---

## ğŸ“Œ What This Project Does

### 1ï¸âƒ£ Scrapes Jobs (RemoteOK)
- Job title
- Company
- Location
- Job URL
- Full job description
- Posted & scraped timestamps

### 2ï¸âƒ£ Stores Data Reliably
- Normalized relational schema
- `jobs`, `companies`, `skills`, `job_skill`
- Duplicate-safe inserts

### 3ï¸âƒ£ Extracts Skill Intelligence
- Regex-based skill extraction from job titles & descriptions
- Aggregates skill demand across all jobs

### 4ï¸âƒ£ Exports Analytics-Ready CSVs
- **Skills summary CSV** (market trends)
- **Jobs export CSV** (full listings)

### 5ï¸âƒ£ Runs Automatically
- GitHub Actions workflow (daily or manual)
- CI-safe execution without database secrets

---

## ğŸ“‚ Project Structure

```text
job-market-scraper/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ scrapers/        # RemoteOK scraper
â”‚   â”œâ”€â”€ models/          # SQLAlchemy models
â”‚   â”œâ”€â”€ repository.py   # DB operations
â”‚   â””â”€â”€ db.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_pipeline.py
â”‚   â”œâ”€â”€ export_jobs_csv.py
â”‚   â”œâ”€â”€ export_skills_csv.py
â”‚   â””â”€â”€ backfill_skills.py
â”œâ”€â”€ alembic/             # DB migrations
â”œâ”€â”€ data/                # Sample CSVs
â”œâ”€â”€ .github/workflows/   # CI automation
â””â”€â”€ README.md
